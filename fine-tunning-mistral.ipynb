{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q transformers ","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:14:48.506755Z","iopub.execute_input":"2024-01-19T15:14:48.507488Z","iopub.status.idle":"2024-01-19T15:15:01.567392Z","shell.execute_reply.started":"2024-01-19T15:14:48.507456Z","shell.execute_reply":"2024-01-19T15:15:01.566199Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -q bitsandbytes","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:01.569407Z","iopub.execute_input":"2024-01-19T15:15:01.569737Z","iopub.status.idle":"2024-01-19T15:15:17.258715Z","shell.execute_reply.started":"2024-01-19T15:15:01.569712Z","shell.execute_reply":"2024-01-19T15:15:17.257692Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"!pip install -q -U peft datasets trl","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:17.260144Z","iopub.execute_input":"2024-01-19T15:15:17.261007Z","iopub.status.idle":"2024-01-19T15:15:32.210985Z","shell.execute_reply.started":"2024-01-19T15:15:17.260970Z","shell.execute_reply":"2024-01-19T15:15:32.210012Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ncuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.0.3 which is incompatible.\ngcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.10.0 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2023.12.0 which is incompatible.\nraft-dask 23.8.0 requires distributed==2023.7.1, but you have distributed 2023.12.0 which is incompatible.\ns3fs 2023.12.2 requires fsspec==2023.12.2, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:32.213442Z","iopub.execute_input":"2024-01-19T15:15:32.213745Z","iopub.status.idle":"2024-01-19T15:15:37.899573Z","shell.execute_reply.started":"2024-01-19T15:15:32.213717Z","shell.execute_reply":"2024-01-19T15:15:37.898559Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# # Modeli Yükleme","metadata":{}},{"cell_type":"code","source":"base_model = \"mistralai/Mistral-7B-v0.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(\n    base_model, \n    padding_side = \"right\",\n    add_eos_token = True,\n)\ntokenizer.pad_token = tokenizer.eos_token\ntokenizer.add_bos_token, tokenizer.add_eos_token","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:37.900975Z","iopub.execute_input":"2024-01-19T15:15:37.901589Z","iopub.status.idle":"2024-01-19T15:15:39.125779Z","shell.execute_reply.started":"2024-01-19T15:15:37.901548Z","shell.execute_reply":"2024-01-19T15:15:39.124858Z"},"trusted":true},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5270b214d49b42598ec82caa6fadcb03"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3bab9a3dde104adc87f6f94344036205"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b610839420547f8a2345245517a9d60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"675d851121654b5691633a4d431cd572"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(True, True)"},"metadata":{}}]},{"cell_type":"code","source":"tokenizer","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:39.126937Z","iopub.execute_input":"2024-01-19T15:15:39.127251Z","iopub.status.idle":"2024-01-19T15:15:39.133033Z","shell.execute_reply.started":"2024-01-19T15:15:39.127220Z","shell.execute_reply":"2024-01-19T15:15:39.132038Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"LlamaTokenizerFast(name_or_path='mistralai/Mistral-7B-v0.1', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import BitsAndBytesConfig\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_use_double_quant=False,\n    bnb_4bit_compute_dtype=torch.bfloat16\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:39.134225Z","iopub.execute_input":"2024-01-19T15:15:39.134494Z","iopub.status.idle":"2024-01-19T15:15:39.147629Z","shell.execute_reply.started":"2024-01-19T15:15:39.134471Z","shell.execute_reply":"2024-01-19T15:15:39.146806Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    base_model,\n    load_in_4bit=True,\n    quantization_config=bnb_config,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:15:39.148517Z","iopub.execute_input":"2024-01-19T15:15:39.148824Z","iopub.status.idle":"2024-01-19T15:16:55.766469Z","shell.execute_reply.started":"2024-01-19T15:15:39.148801Z","shell.execute_reply":"2024-01-19T15:16:55.765646Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bdbe66e9ab16452bbacc22f0c75068a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ddd891c1ac446ab8191e7fb46f701ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"730e5e2ac48b4694a437c3bf0dc6a28b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44d3616e533042f0ab39cce06cd988a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"55b54904540940b4a6854f4f80852fd3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b774c8c027d4be8a109e35330bd7fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6445eaf999942a3bbfd7a94be7215c9"}},"metadata":{}}]},{"cell_type":"markdown","source":"# # Dataseti Yükleme","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\ndataset_name = \"databricks/databricks-dolly-15k\"\n\ntrain_dataset = load_dataset(dataset_name, split=\"train[0:800]\")\neval_dataset = load_dataset(dataset_name, split=\"train[800:1000]\")","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:16:55.767643Z","iopub.execute_input":"2024-01-19T15:16:55.768076Z","iopub.status.idle":"2024-01-19T15:17:01.520051Z","shell.execute_reply.started":"2024-01-19T15:16:55.768048Z","shell.execute_reply":"2024-01-19T15:17:01.519093Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/8.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ec837fe9e774c40972b7313f9ff79ff"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/13.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a7ca9c1726694f71a8547ee9989092f2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split: 0 examples [00:00, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b8b783640be4b05950ac5ce6e0523bf"}},"metadata":{}}]},{"cell_type":"code","source":"train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.523731Z","iopub.execute_input":"2024-01-19T15:17:01.524171Z","iopub.status.idle":"2024-01-19T15:17:01.529896Z","shell.execute_reply.started":"2024-01-19T15:17:01.524145Z","shell.execute_reply":"2024-01-19T15:17:01.528939Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['instruction', 'context', 'response', 'category'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.531380Z","iopub.execute_input":"2024-01-19T15:17:01.531752Z","iopub.status.idle":"2024-01-19T15:17:01.590288Z","shell.execute_reply.started":"2024-01-19T15:17:01.531719Z","shell.execute_reply":"2024-01-19T15:17:01.589248Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"                                           instruction  \\\n0           When did Virgin Australia start operating?   \n1             Which is a species of fish? Tope or Rope   \n2       Why can camels survive for long without water?   \n3    Alice's parents have three daughters: Amy, Jes...   \n4                      When was Tomoaki Komorida born?   \n..                                                 ...   \n795         Who is the founder of the Communist Party?   \n796                                 What is gardening?   \n797  What are your thoughts of Michael Jackson as a...   \n798                     What is the largest pollutant?   \n799                        Why do people drink coffee?   \n\n                                               context  \\\n0    Virgin Australia, the trading name of Virgin A...   \n1                                                        \n2                                                        \n3                                                        \n4    Komorida was born in Kumamoto Prefecture on Ju...   \n..                                                 ...   \n795                                                      \n796  Gardening is the practice of growing and culti...   \n797                                                      \n798                                                      \n799                                                      \n\n                                              response                category  \n0    Virgin Australia commenced services on 31 Augu...               closed_qa  \n1                                                 Tope          classification  \n2    Camels use the fat in their humps to keep them...                 open_qa  \n3              The name of the third daughter is Alice                 open_qa  \n4           Tomoaki Komorida was born on July 10,1981.               closed_qa  \n..                                                 ...                     ...  \n795                                              Lenin                 open_qa  \n796  Gardening is laying out and caring for a plot ...  information_extraction  \n797  Michael Jackson is acclaimed as the greatest p...        creative_writing  \n798  Carbon dioxide (CO2) - a greenhouse gas emitte...              general_qa  \n799  Coffee contains caffeine which is a stimulant....              general_qa  \n\n[800 rows x 4 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>instruction</th>\n      <th>context</th>\n      <th>response</th>\n      <th>category</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>When did Virgin Australia start operating?</td>\n      <td>Virgin Australia, the trading name of Virgin A...</td>\n      <td>Virgin Australia commenced services on 31 Augu...</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Which is a species of fish? Tope or Rope</td>\n      <td></td>\n      <td>Tope</td>\n      <td>classification</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Why can camels survive for long without water?</td>\n      <td></td>\n      <td>Camels use the fat in their humps to keep them...</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alice's parents have three daughters: Amy, Jes...</td>\n      <td></td>\n      <td>The name of the third daughter is Alice</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>When was Tomoaki Komorida born?</td>\n      <td>Komorida was born in Kumamoto Prefecture on Ju...</td>\n      <td>Tomoaki Komorida was born on July 10,1981.</td>\n      <td>closed_qa</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>795</th>\n      <td>Who is the founder of the Communist Party?</td>\n      <td></td>\n      <td>Lenin</td>\n      <td>open_qa</td>\n    </tr>\n    <tr>\n      <th>796</th>\n      <td>What is gardening?</td>\n      <td>Gardening is the practice of growing and culti...</td>\n      <td>Gardening is laying out and caring for a plot ...</td>\n      <td>information_extraction</td>\n    </tr>\n    <tr>\n      <th>797</th>\n      <td>What are your thoughts of Michael Jackson as a...</td>\n      <td></td>\n      <td>Michael Jackson is acclaimed as the greatest p...</td>\n      <td>creative_writing</td>\n    </tr>\n    <tr>\n      <th>798</th>\n      <td>What is the largest pollutant?</td>\n      <td></td>\n      <td>Carbon dioxide (CO2) - a greenhouse gas emitte...</td>\n      <td>general_qa</td>\n    </tr>\n    <tr>\n      <th>799</th>\n      <td>Why do people drink coffee?</td>\n      <td></td>\n      <td>Coffee contains caffeine which is a stimulant....</td>\n      <td>general_qa</td>\n    </tr>\n  </tbody>\n</table>\n<p>800 rows × 4 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().dtypes","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.591296Z","iopub.execute_input":"2024-01-19T15:17:01.591562Z","iopub.status.idle":"2024-01-19T15:17:01.601908Z","shell.execute_reply.started":"2024-01-19T15:17:01.591538Z","shell.execute_reply":"2024-01-19T15:17:01.600953Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"instruction    object\ncontext        object\nresponse       object\ncategory       object\ndtype: object"},"metadata":{}}]},{"cell_type":"code","source":"train_dataset.to_pandas().value_counts(\"category\")","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.603363Z","iopub.execute_input":"2024-01-19T15:17:01.603742Z","iopub.status.idle":"2024-01-19T15:17:01.616562Z","shell.execute_reply.started":"2024-01-19T15:17:01.603708Z","shell.execute_reply":"2024-01-19T15:17:01.615684Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"category\nopen_qa                   202\ngeneral_qa                132\nclassification            111\nbrainstorming              95\nclosed_qa                  90\ninformation_extraction     68\nsummarization              63\ncreative_writing           39\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"markdown","source":"# # Metin Üretme Formatının Oluşturulması","metadata":{}},{"cell_type":"code","source":"def generate_prompt(sample):\n    full_prompt =f\"\"\"<s>[INST]{sample['instruction']}\n    {f\"Here is some context: {sample['context']}\" if len(sample[\"context\"]) > 0 else None}\n    [/INST] {sample['response']}</s>\"\"\"\n    return {\"text\": full_prompt}","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.617620Z","iopub.execute_input":"2024-01-19T15:17:01.617892Z","iopub.status.idle":"2024-01-19T15:17:01.623607Z","shell.execute_reply.started":"2024-01-19T15:17:01.617867Z","shell.execute_reply":"2024-01-19T15:17:01.622682Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.624661Z","iopub.execute_input":"2024-01-19T15:17:01.625048Z","iopub.status.idle":"2024-01-19T15:17:01.636286Z","shell.execute_reply.started":"2024-01-19T15:17:01.625015Z","shell.execute_reply":"2024-01-19T15:17:01.635391Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"{'instruction': 'When did Virgin Australia start operating?',\n 'context': \"Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\",\n 'response': 'Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.',\n 'category': 'closed_qa'}"},"metadata":{}}]},{"cell_type":"code","source":"print(generate_prompt(train_dataset[0]))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.637338Z","iopub.execute_input":"2024-01-19T15:17:01.637594Z","iopub.status.idle":"2024-01-19T15:17:01.647992Z","shell.execute_reply.started":"2024-01-19T15:17:01.637572Z","shell.execute_reply":"2024-01-19T15:17:01.647152Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'text': \"<s>[INST]When did Virgin Australia start operating?\\n    Here is some context: Virgin Australia, the trading name of Virgin Australia Airlines Pty Ltd, is an Australian-based airline. It is the largest airline by fleet size to use the Virgin brand. It commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route. It suddenly found itself as a major airline in Australia's domestic market after the collapse of Ansett Australia in September 2001. The airline has since grown to directly serve 32 cities in Australia, from hubs in Brisbane, Melbourne and Sydney.\\n    [/INST] Virgin Australia commenced services on 31 August 2000 as Virgin Blue, with two aircraft on a single route.</s>\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"generated_train_dataset = train_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))\ngenerated_val_dataset = eval_dataset.map(\n    generate_prompt, remove_columns=list(train_dataset.features))","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.649088Z","iopub.execute_input":"2024-01-19T15:17:01.649382Z","iopub.status.idle":"2024-01-19T15:17:01.780289Z","shell.execute_reply.started":"2024-01-19T15:17:01.649358Z","shell.execute_reply":"2024-01-19T15:17:01.779384Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1100370dfad41f8b74f784d6803aab2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4cb39d94a52248c7abca49b703a8859d"}},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.781533Z","iopub.execute_input":"2024-01-19T15:17:01.782137Z","iopub.status.idle":"2024-01-19T15:17:01.788005Z","shell.execute_reply.started":"2024-01-19T15:17:01.782095Z","shell.execute_reply":"2024-01-19T15:17:01.787091Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text'],\n    num_rows: 800\n})"},"metadata":{}}]},{"cell_type":"code","source":"generated_train_dataset[5][\"text\"]","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.789089Z","iopub.execute_input":"2024-01-19T15:17:01.789445Z","iopub.status.idle":"2024-01-19T15:17:01.801837Z","shell.execute_reply.started":"2024-01-19T15:17:01.789419Z","shell.execute_reply":"2024-01-19T15:17:01.800985Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"\"<s>[INST]If I have more pieces at the time of stalemate, have I won?\\n    Here is some context: Stalemate is a situation in chess where the player whose turn it is to move is not in check and has no legal move. Stalemate results in a draw. During the endgame, stalemate is a resource that can enable the player with the inferior position to draw the game rather than lose. In more complex positions, stalemate is much rarer, usually taking the form of a swindle that succeeds only if the superior side is inattentive.[citation needed] Stalemate is also a common theme in endgame studies and other chess problems.\\n\\nThe outcome of a stalemate was standardized as a draw in the 19th century. Before this standardization, its treatment varied widely, including being deemed a win for the stalemating player, a half-win for that player, or a loss for that player; not being permitted; and resulting in the stalemated player missing a turn. Stalemate rules vary in other games of the chess family.\\n    [/INST] No. \\nStalemate is a drawn position. It doesn't matter who has captured more pieces or is in a winning position</s>\""},"metadata":{}}]},{"cell_type":"code","source":"tokenizer(generated_train_dataset[5][\"text\"])","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.802848Z","iopub.execute_input":"2024-01-19T15:17:01.803146Z","iopub.status.idle":"2024-01-19T15:17:01.818330Z","shell.execute_reply.started":"2024-01-19T15:17:01.803118Z","shell.execute_reply":"2024-01-19T15:17:01.817321Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"{'input_ids': [1, 1, 733, 16289, 28793, 3381, 315, 506, 680, 7769, 438, 272, 727, 302, 341, 282, 366, 380, 28725, 506, 315, 1747, 28804, 13, 2287, 4003, 349, 741, 2758, 28747, 662, 282, 366, 380, 349, 264, 4620, 297, 997, 819, 970, 272, 4385, 4636, 1527, 378, 349, 298, 2318, 349, 459, 297, 1877, 304, 659, 708, 5648, 2318, 28723, 662, 282, 366, 380, 2903, 297, 264, 3924, 28723, 6213, 272, 948, 8835, 28725, 341, 282, 366, 380, 349, 264, 3715, 369, 541, 8234, 272, 4385, 395, 272, 24797, 2840, 298, 3924, 272, 2039, 3210, 821, 6788, 28723, 560, 680, 4630, 9161, 28725, 341, 282, 366, 380, 349, 1188, 408, 283, 263, 28725, 4312, 3344, 272, 1221, 302, 264, 1719, 507, 291, 369, 9481, 28713, 865, 513, 272, 11352, 2081, 349, 297, 1061, 308, 495, 20011, 28717, 5174, 3236, 28793, 662, 282, 366, 380, 349, 835, 264, 3298, 7335, 297, 948, 8835, 7193, 304, 799, 997, 819, 4418, 28723, 13, 13, 1014, 14120, 302, 264, 341, 282, 366, 380, 403, 4787, 1332, 390, 264, 3924, 297, 272, 28705, 28740, 28774, 362, 5445, 28723, 7337, 456, 4787, 1837, 28725, 871, 5827, 20331, 12575, 28725, 2490, 1250, 24328, 264, 3108, 354, 272, 341, 282, 366, 1077, 4385, 28725, 264, 2795, 28733, 5162, 354, 369, 4385, 28725, 442, 264, 4320, 354, 369, 4385, 28745, 459, 1250, 15463, 28745, 304, 10503, 297, 272, 341, 282, 366, 601, 4385, 6925, 264, 1527, 28723, 662, 282, 366, 380, 5879, 11204, 297, 799, 3897, 302, 272, 997, 819, 2005, 28723, 13, 2287, 733, 28748, 16289, 28793, 1770, 28723, 28705, 13, 718, 282, 366, 380, 349, 264, 10421, 2840, 28723, 661, 2368, 28742, 28707, 3209, 693, 659, 13382, 680, 7769, 442, 349, 297, 264, 9821, 2840, 2, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"},"metadata":{}}]},{"cell_type":"markdown","source":"# # LoRA Konfigürasyonu\n","metadata":{}},{"cell_type":"code","source":"from peft import prepare_model_for_kbit_training\n\nmodel.gradient_checkpointing_enable()\n\nmodel = prepare_model_for_kbit_training(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.819445Z","iopub.execute_input":"2024-01-19T15:17:01.820241Z","iopub.status.idle":"2024-01-19T15:17:01.900447Z","shell.execute_reply.started":"2024-01-19T15:17:01.820208Z","shell.execute_reply":"2024-01-19T15:17:01.899507Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def print_trainable_parameters(model):\n    trainable_params = 0\n    all_param = 0\n    for _, param in model.named_parameters():\n        all_param += param.numel()\n        if param.requires_grad:\n            trainable_params += param.numel()\n    print(\n        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n    )","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.901663Z","iopub.execute_input":"2024-01-19T15:17:01.901998Z","iopub.status.idle":"2024-01-19T15:17:01.907931Z","shell.execute_reply.started":"2024-01-19T15:17:01.901966Z","shell.execute_reply":"2024-01-19T15:17:01.907019Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"from peft import LoraConfig, get_peft_model\n    \nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\n        \"q_proj\",\n        \"k_proj\",\n        \"v_proj\",\n        \"o_proj\",\n        \"gate_proj\",\n        \"up_proj\",\n        \"down_proj\",\n        \"lm_head\",\n    ],\n    bias=\"none\",\n    lora_dropout=0.05, \n    task_type=\"CAUSAL_LM\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.909122Z","iopub.execute_input":"2024-01-19T15:17:01.909433Z","iopub.status.idle":"2024-01-19T15:17:01.920043Z","shell.execute_reply.started":"2024-01-19T15:17:01.909408Z","shell.execute_reply":"2024-01-19T15:17:01.919092Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"from peft import get_peft_model\n\nmodel = get_peft_model(model, lora_config)\n\nprint_trainable_parameters(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:01.921184Z","iopub.execute_input":"2024-01-19T15:17:01.921496Z","iopub.status.idle":"2024-01-19T15:17:02.547315Z","shell.execute_reply.started":"2024-01-19T15:17:01.921472Z","shell.execute_reply":"2024-01-19T15:17:02.546419Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"trainable params: 21260288 || all params: 3773331456 || trainable%: 0.5634354746703705\n","output_type":"stream"}]},{"cell_type":"code","source":"print(model)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:02.548385Z","iopub.execute_input":"2024-01-19T15:17:02.548653Z","iopub.status.idle":"2024-01-19T15:17:02.567957Z","shell.execute_reply.started":"2024-01-19T15:17:02.548619Z","shell.execute_reply":"2024-01-19T15:17:02.567118Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"PeftModelForCausalLM(\n  (base_model): LoraModel(\n    (model): MistralForCausalLM(\n      (model): MistralModel(\n        (embed_tokens): Embedding(32000, 4096)\n        (layers): ModuleList(\n          (0-31): 32 x MistralDecoderLayer(\n            (self_attn): MistralAttention(\n              (q_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (k_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (v_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=1024, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=1024, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (o_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (rotary_emb): MistralRotaryEmbedding()\n            )\n            (mlp): MistralMLP(\n              (gate_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (up_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=4096, out_features=14336, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=4096, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=14336, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (down_proj): lora.Linear4bit(\n                (base_layer): Linear4bit(in_features=14336, out_features=4096, bias=False)\n                (lora_dropout): ModuleDict(\n                  (default): Dropout(p=0.05, inplace=False)\n                )\n                (lora_A): ModuleDict(\n                  (default): Linear(in_features=14336, out_features=8, bias=False)\n                )\n                (lora_B): ModuleDict(\n                  (default): Linear(in_features=8, out_features=4096, bias=False)\n                )\n                (lora_embedding_A): ParameterDict()\n                (lora_embedding_B): ParameterDict()\n              )\n              (act_fn): SiLU()\n            )\n            (input_layernorm): MistralRMSNorm()\n            (post_attention_layernorm): MistralRMSNorm()\n          )\n        )\n        (norm): MistralRMSNorm()\n      )\n      (lm_head): lora.Linear(\n        (base_layer): Linear(in_features=4096, out_features=32000, bias=False)\n        (lora_dropout): ModuleDict(\n          (default): Dropout(p=0.05, inplace=False)\n        )\n        (lora_A): ModuleDict(\n          (default): Linear(in_features=4096, out_features=8, bias=False)\n        )\n        (lora_B): ModuleDict(\n          (default): Linear(in_features=8, out_features=32000, bias=False)\n        )\n        (lora_embedding_A): ParameterDict()\n        (lora_embedding_B): ParameterDict()\n      )\n    )\n  )\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# # Model Training","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:53:29.653594Z","iopub.status.idle":"2024-01-19T15:53:29.653956Z","shell.execute_reply.started":"2024-01-19T15:53:29.653782Z","shell.execute_reply":"2024-01-19T15:53:29.653800Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\ntraining_arguments = TrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=4,\n    gradient_accumulation_steps=1,\n    optim=\"paged_adamw_32bit\",\n    save_strategy=\"steps\",\n    save_steps=25,\n    logging_steps=25,\n    learning_rate=2e-4,\n    weight_decay=0.001,\n    max_steps=50,\n    evaluation_strategy=\"steps\", \n    eval_steps=25,       \n    do_eval=True,               \n    report_to=\"none\",\n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:02.604738Z","iopub.execute_input":"2024-01-19T15:17:02.605401Z","iopub.status.idle":"2024-01-19T15:17:02.624974Z","shell.execute_reply.started":"2024-01-19T15:17:02.605365Z","shell.execute_reply":"2024-01-19T15:17:02.624223Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\n\n# Setting sft parameters\ntrainer = SFTTrainer(\n    model=model,\n    tokenizer=tokenizer,\n    args=training_arguments,\n    train_dataset=generated_train_dataset,\n    eval_dataset=generated_val_dataset,\n    peft_config=lora_config,\n    dataset_text_field=\"text\",   \n)","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:02.629166Z","iopub.execute_input":"2024-01-19T15:17:02.629471Z","iopub.status.idle":"2024-01-19T15:17:15.872601Z","shell.execute_reply.started":"2024-01-19T15:17:02.629446Z","shell.execute_reply":"2024-01-19T15:17:15.871733Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:223: UserWarning: You didn't pass a `max_seq_length` argument to the SFTTrainer, this will default to 1024\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9d4427e8413440ba45472f7b7d33431"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/200 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9ff64c375984d8dacaffd0154dcb7e4"}},"metadata":{}}]},{"cell_type":"code","source":"model.config.use_cache = False\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-01-19T15:17:15.873836Z","iopub.execute_input":"2024-01-19T15:17:15.874216Z","iopub.status.idle":"2024-01-19T15:53:27.288706Z","shell.execute_reply.started":"2024-01-19T15:17:15.874164Z","shell.execute_reply":"2024-01-19T15:53:27.287748Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stderr","text":"You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [50/50 36:01, Epoch 0/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>25</td>\n      <td>1.516300</td>\n      <td>1.505404</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>1.524700</td>\n      <td>1.469396</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n/opt/conda/lib/python3.10/site-packages/peft/utils/save_and_load.py:131: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n","output_type":"stream"},{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=50, training_loss=1.5205093383789063, metrics={'train_runtime': 2171.0473, 'train_samples_per_second': 0.092, 'train_steps_per_second': 0.023, 'total_flos': 3719610284752896.0, 'train_loss': 1.5205093383789063, 'epoch': 0.25})"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}